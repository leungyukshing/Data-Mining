{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义回归决策树\n",
    "算法介绍：CART回归树样本空间细分为若干个子空间，子空间内样本的输出y（连续值）的均值即为该子空间内的预测值。故对于输入X为一维时，预测结果可表示为阶梯函数。  \n",
    "评估方式采用**平方误差**：$y_i$属于某个数据集，c为该数据上输出向量y的均值。\n",
    "$$\n",
    "err = \\sum(y_i - c)^2\n",
    "$$\n",
    "\n",
    "算法过程：  \n",
    "输入：训练数据集$D$；  \n",
    "输出：回归树$f(x)$  \n",
    "在训练数据集所在的输入空间中，递归地将每个区域划分为两个子区域并决定每个子区域上的输出值，构建二叉决策树：  \n",
    "（1）选择最优切分变量$j$与切分点$s$，求解\n",
    "$$\n",
    "\\min_{j,s}[\\min_{c_1}\\sum_{x_i\\in R_1(j,s)}(y_i - c_1)^2 + \\min_{c_2}\\sum_{x_i\\in R_2(j, s)}(y_i-c_2)^2]\n",
    "$$\n",
    "遍历变量$j$，对固定的切分变量扫描切分点$s$，选择使得上式达到最小值的对$(j,s)$.  \n",
    "（2）用选定的对$(j,s)$划分区域并决定相应的输出值：\n",
    "$$\n",
    "R_1(j,s) = \\{x|x^{(j)} \\le s \\},R_2(j,s) = \\{x|x^{(j)} \\gt s \\} \\\\\n",
    "\\hat{c}_m = \\frac{1}{N_m} \\sum_{x_i\\in R_m(j, s) y_i}, x \\in R_m, m=1,2\n",
    "$$  \n",
    "（3）继续对两个子区域调用步骤（1）和（2），直至满足停止条件  \n",
    "（4）将输入空间划分为$M$个区域$R_1, R_2, \\dots, R_M$，生成决策树：\n",
    "$$\n",
    "f(x) = \\sum^M_{m=1}\\hat{c}_mI(x\\in R_m)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最小二乘损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def err(dataSet):\n",
    "    return np.var(dataSet[:, -1]) * dataSet.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataSet(dataSet, feature, value):\n",
    "    '''\n",
    "    Input:\n",
    "        dataSet：当前数据集\n",
    "        feature：切分变量[列名]\n",
    "        value：划分点\n",
    "    Output:\n",
    "        dataSet1：在feature上<=value的子数据集\n",
    "        dataSet2：在feature上>value的子数据集\n",
    "    '''\n",
    "    dataSet1 = dataSet[dataSet[:, feature] <= value] # 左边\n",
    "    dataSet2 = dataSet[dataSet[:, feature] > value] # 右边\n",
    "    return dataSet1, dataSet2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选择最好的特征用于划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestFeature(dataSet, min_sample=4, epsilon=0.5):\n",
    "    '''\n",
    "    Input:\n",
    "        dataSet：当前数据集\n",
    "        min_sample：每次划分后，每部分最少的数据数量\n",
    "        epsilon：误差下降阈值，值越大树的深度越大\n",
    "    Output:\n",
    "        bestColumn：最优划分属性\n",
    "        bestValue：最优划分点\n",
    "    '''\n",
    "    featrues = dataSet.shape[1] - 1 # 特征数量（除去最后一列的标签值）\n",
    "    sErr = err(dataSet) # 当前数据集的损失\n",
    "    minErr = np.inf # 初始化最小误差\n",
    "    bestColumn = 0 # 最优划分特征\n",
    "    bestValue = 0 # 最优划分值\n",
    "    nowErr = 0 # 当前误差\n",
    "    \n",
    "    # 如果数据都是一类，无须进行划分\n",
    "    if len(np.unique(dataSet[:, -1].T.tolist())) == 1:\n",
    "        return None, np.mean(dataSet[:, -1])\n",
    "    # 每个特征循环，寻找最优特征\n",
    "    for feature in range(0, features):\n",
    "        # 遍历每一行数据，寻找最优划分点\n",
    "        for row in range(0, dataSet.shape[0]):\n",
    "            dataSet1, dataSet2 = splitDataSet(dataSet, feature, dataSet[row, feature]) # 划分后的数据\n",
    "            # 不满足min_sample，直接跳过这种不合法的划分\n",
    "            if len(dataSet1) < min_sample or len(dataSet2) < min_sample:\n",
    "                continue\n",
    "            # 计算当前这种划分的误差\n",
    "            nowErr = err(dataSet1) + err(dataSet2)\n",
    "            # 维护最优的划分（最优属性和对应的最优划分点）\n",
    "            if nowErr < minErr:\n",
    "                minErr = nowErr\n",
    "                bestColumn = feature\n",
    "                bestValue = dataSet[row, feature]\n",
    "    # 当划分前后误差下降较小时，直接返回\n",
    "    if (sErr - minErr) < epsilon:\n",
    "        return None, np.mean(dataSetp[:, -1])\n",
    "    \n",
    "    # 获得当前最优划分\n",
    "    dataSet1, dataSet2 = splitDataSet(dataSet, bestColumn, bestValue)\n",
    "    if len(dataSet1) < min_sample or len(dataSet2) < min_sample:\n",
    "        return None, np.mean(dataSet[:, -1])\n",
    "    \n",
    "    return bestColumn, bestValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建回归树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(dataSet):\n",
    "    '''\n",
    "    Input:\n",
    "        dataSet: 数据集D\n",
    "    Output:\n",
    "        决策树T\n",
    "    '''\n",
    "    bestColumn, bestValue = chooseBestFeature(dataSet)\n",
    "    if bestColumn == None:\n",
    "        return bestValue\n",
    "    retTree = {} # 初始化决策树\n",
    "    retTree['spCol'] = bestColumn # 最优划分属性（列）\n",
    "    retTree['spVal'] = bestValue # 最优分割值\n",
    "    lSet,rSet = splitDataSet(dataSet, bestColumn, bestValue) # 最优划分\n",
    "    retTree['left'] = createTree(lSet)\n",
    "    retTree['right'] = createTree(rSet)\n",
    "    return retTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(tree, testData):\n",
    "    if shape(testData)[0] == 0:\n",
    "        return getMean(tree)\n",
    "    if (isTree(tree['right']) or isTree(tree['left'])):\n",
    "        lSet, rSet = splitDataSet(testData, tree['spCol'], tree['spVal'])\n",
    "    if isTree(tree['left']):\n",
    "        tree['left'] = prune(tree['left'], lSet)\n",
    "    if isTree(tree['right']):\n",
    "        tree['right'] = prune(tree['right'], rSet)\n",
    "        \n",
    "    # 如果两个分支不再是子树，合并\n",
    "    # 合并前后的误差进行比较，如果合并后的误差比较小，则合并，否则不操作\n",
    "    if not isTree(tree['left']) and not isTree(tree['right']):\n",
    "        lSet, rSet = splitDataSet(testData, tree['spCol'], tree['spVal'])\n",
    "        errMerge = err(dataSet)\n",
    "        errNoMerge = err(lSet) + err(rSet)\n",
    "        if errMerge > errNoMerge:\n",
    "            print('merging')\n",
    "            return (tree['left'] + tree['right']) / 2.0\n",
    "        else:\n",
    "            return tree\n",
    "        \n",
    "def isTree(obj):\n",
    "    return (type(obj).__name__ == 'dict')\n",
    "\n",
    "def getMean(obj):\n",
    "    if isTree(tree['right']):\n",
    "        tree['right'] = getMean(tree['right'])\n",
    "        tree['left'] = getMean(tree['left'])\n",
    "        return (tree['left'] + tree['right']) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
