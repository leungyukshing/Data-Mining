{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义回归决策树MyRegressionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree.tree import BaseDecisionTree\n",
    "from sklearn.base import RegressorMixin\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.tree.tree import _tree, _splitter, _criterion\n",
    "from sklearn.tree._criterion import Criterion\n",
    "from sklearn.tree._splitter import Splitter\n",
    "from sklearn.tree._tree import Tree, DepthFirstTreeBuilder, BestFirstTreeBuilder\n",
    "import numpy as np\n",
    "import numbers\n",
    "from scipy.sparse import issparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOUBLE = _tree.DOUBLE\n",
    "CRITERIA_REG = {\"mse\": _criterion.MSE, \"friedman_mse\": _criterion.FriedmanMSE,\n",
    "                \"mae\": _criterion.MAE}\n",
    "DENSE_SPLITTERS = {\"best\": _splitter.BestSplitter,\n",
    "                   \"random\": _splitter.RandomSplitter}\n",
    "\n",
    "class MyRegressionTree(BaseDecisionTree, RegressorMixin):\n",
    "    def __init__(self,\n",
    "                 criterion=\"mse\",\n",
    "                 splitter=\"best\",\n",
    "                 max_depth=None,\n",
    "                 min_samples_split=2,\n",
    "                 min_samples_leaf=1,\n",
    "                 min_weight_fraction_leaf=0.,\n",
    "                 max_features=None,\n",
    "                 random_state=None,\n",
    "                 max_leaf_nodes=None,\n",
    "                 min_impurity_decrease=0.,\n",
    "                 min_impurity_split=None,\n",
    "                 presort=False):\n",
    "        super().__init__(\n",
    "            criterion=criterion,\n",
    "            splitter=splitter,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "            max_features=max_features,\n",
    "            max_leaf_nodes=max_leaf_nodes,\n",
    "            random_state=random_state,\n",
    "            min_impurity_decrease=min_impurity_decrease,\n",
    "            min_impurity_split=min_impurity_split,\n",
    "            presort=presort)\n",
    "        \n",
    "    def fit(self, X, y, sample_weight=None, check_input=True, X_idx_sorted=None):\n",
    "        random_state = check_random_state(self.random_state)\n",
    "        # Determine output settings\n",
    "        n_samples, self.n_features_ = X.shape\n",
    "        # is_classification = is_classifier(self)\n",
    "\n",
    "        y = np.atleast_1d(y)\n",
    "        expanded_class_weight = None\n",
    "\n",
    "        if y.ndim == 1:\n",
    "            # reshape is necessary to preserve the data contiguity against vs\n",
    "            # [:, np.newaxis] that does not.\n",
    "            y = np.reshape(y, (-1, 1))\n",
    "\n",
    "        self.n_outputs_ = y.shape[1]\n",
    "        '''\n",
    "        if is_classification:\n",
    "            check_classification_targets(y)\n",
    "            y = np.copy(y)\n",
    "\n",
    "            self.classes_ = []\n",
    "            self.n_classes_ = []\n",
    "\n",
    "            if self.class_weight is not None:\n",
    "                y_original = np.copy(y)\n",
    "\n",
    "            y_encoded = np.zeros(y.shape, dtype=np.int)\n",
    "            for k in range(self.n_outputs_):\n",
    "                classes_k, y_encoded[:, k] = np.unique(y[:, k],\n",
    "                                                       return_inverse=True)\n",
    "                self.classes_.append(classes_k)\n",
    "                self.n_classes_.append(classes_k.shape[0])\n",
    "            y = y_encoded\n",
    "\n",
    "            if self.class_weight is not None:\n",
    "                expanded_class_weight = compute_sample_weight(\n",
    "                    self.class_weight, y_original)\n",
    "        '''\n",
    "        #else:\n",
    "        self.classes_ = [None] * self.n_outputs_\n",
    "        self.n_classes_ = [1] * self.n_outputs_\n",
    "\n",
    "        self.n_classes_ = np.array(self.n_classes_, dtype=np.intp)\n",
    "\n",
    "        if getattr(y, \"dtype\", None) != DOUBLE or not y.flags.contiguous:\n",
    "            y = np.ascontiguousarray(y, dtype=DOUBLE)\n",
    "\n",
    "        # Check parameters\n",
    "        max_depth = ((2 ** 31) - 1 if self.max_depth is None\n",
    "                     else self.max_depth)\n",
    "        max_leaf_nodes = (-1 if self.max_leaf_nodes is None\n",
    "                          else self.max_leaf_nodes)\n",
    "\n",
    "        if isinstance(self.min_samples_leaf, (numbers.Integral, np.integer)):\n",
    "            if not 1 <= self.min_samples_leaf:\n",
    "                raise ValueError(\"min_samples_leaf must be at least 1 \"\n",
    "                                 \"or in (0, 0.5], got %s\"\n",
    "                                 % self.min_samples_leaf)\n",
    "            min_samples_leaf = self.min_samples_leaf\n",
    "        else:  # float\n",
    "            if not 0. < self.min_samples_leaf <= 0.5:\n",
    "                raise ValueError(\"min_samples_leaf must be at least 1 \"\n",
    "                                 \"or in (0, 0.5], got %s\"\n",
    "                                 % self.min_samples_leaf)\n",
    "            min_samples_leaf = int(ceil(self.min_samples_leaf * n_samples))\n",
    "\n",
    "        if isinstance(self.min_samples_split, (numbers.Integral, np.integer)):\n",
    "            if not 2 <= self.min_samples_split:\n",
    "                raise ValueError(\"min_samples_split must be an integer \"\n",
    "                                 \"greater than 1 or a float in (0.0, 1.0]; \"\n",
    "                                 \"got the integer %s\"\n",
    "                                 % self.min_samples_split)\n",
    "            min_samples_split = self.min_samples_split\n",
    "        else:  # float\n",
    "            if not 0. < self.min_samples_split <= 1.:\n",
    "                raise ValueError(\"min_samples_split must be an integer \"\n",
    "                                 \"greater than 1 or a float in (0.0, 1.0]; \"\n",
    "                                 \"got the float %s\"\n",
    "                                 % self.min_samples_split)\n",
    "            min_samples_split = int(ceil(self.min_samples_split * n_samples))\n",
    "            min_samples_split = max(2, min_samples_split)\n",
    "\n",
    "        min_samples_split = max(min_samples_split, 2 * min_samples_leaf)\n",
    "\n",
    "        if isinstance(self.max_features, str):\n",
    "            if self.max_features == \"auto\":\n",
    "                '''\n",
    "                if is_classification:\n",
    "                    max_features = max(1, int(np.sqrt(self.n_features_)))\n",
    "                else:\n",
    "                '''\n",
    "                max_features = self.n_features_\n",
    "            elif self.max_features == \"sqrt\":\n",
    "                max_features = max(1, int(np.sqrt(self.n_features_)))\n",
    "            elif self.max_features == \"log2\":\n",
    "                max_features = max(1, int(np.log2(self.n_features_)))\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    'Invalid value for max_features. Allowed string '\n",
    "                    'values are \"auto\", \"sqrt\" or \"log2\".')\n",
    "        elif self.max_features is None:\n",
    "            max_features = self.n_features_\n",
    "        elif isinstance(self.max_features, (numbers.Integral, np.integer)):\n",
    "            max_features = self.max_features\n",
    "        else:  # float\n",
    "            if self.max_features > 0.0:\n",
    "                max_features = max(1,\n",
    "                                   int(self.max_features * self.n_features_))\n",
    "            else:\n",
    "                max_features = 0\n",
    "\n",
    "        self.max_features_ = max_features\n",
    "\n",
    "        if len(y) != n_samples:\n",
    "            raise ValueError(\"Number of labels=%d does not match \"\n",
    "                             \"number of samples=%d\" % (len(y), n_samples))\n",
    "        if not 0 <= self.min_weight_fraction_leaf <= 0.5:\n",
    "            raise ValueError(\"min_weight_fraction_leaf must in [0, 0.5]\")\n",
    "        if max_depth <= 0:\n",
    "            raise ValueError(\"max_depth must be greater than zero. \")\n",
    "        if not (0 < max_features <= self.n_features_):\n",
    "            raise ValueError(\"max_features must be in (0, n_features]\")\n",
    "        if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):\n",
    "            raise ValueError(\"max_leaf_nodes must be integral number but was \"\n",
    "                             \"%r\" % max_leaf_nodes)\n",
    "        if -1 < max_leaf_nodes < 2:\n",
    "            raise ValueError((\"max_leaf_nodes {0} must be either None \"\n",
    "                              \"or larger than 1\").format(max_leaf_nodes))\n",
    "\n",
    "        if sample_weight is not None:\n",
    "            if (getattr(sample_weight, \"dtype\", None) != DOUBLE or\n",
    "                    not sample_weight.flags.contiguous):\n",
    "                sample_weight = np.ascontiguousarray(\n",
    "                    sample_weight, dtype=DOUBLE)\n",
    "            if len(sample_weight.shape) > 1:\n",
    "                raise ValueError(\"Sample weights array has more \"\n",
    "                                 \"than one dimension: %d\" %\n",
    "                                 len(sample_weight.shape))\n",
    "            if len(sample_weight) != n_samples:\n",
    "                raise ValueError(\"Number of weights=%d does not match \"\n",
    "                                 \"number of samples=%d\" %\n",
    "                                 (len(sample_weight), n_samples))\n",
    "\n",
    "        if expanded_class_weight is not None:\n",
    "            if sample_weight is not None:\n",
    "                sample_weight = sample_weight * expanded_class_weight\n",
    "            else:\n",
    "                sample_weight = expanded_class_weight\n",
    "\n",
    "        # Set min_weight_leaf from min_weight_fraction_leaf\n",
    "        if sample_weight is None:\n",
    "            min_weight_leaf = (self.min_weight_fraction_leaf *\n",
    "                               n_samples)\n",
    "        else:\n",
    "            min_weight_leaf = (self.min_weight_fraction_leaf *\n",
    "                               np.sum(sample_weight))    \n",
    "        \n",
    "        if self.min_impurity_split is not None:\n",
    "            warnings.warn(\"The min_impurity_split parameter is deprecated. \"\n",
    "                          \"Its default value will change from 1e-7 to 0 in \"\n",
    "                          \"version 0.23, and it will be removed in 0.25. \"\n",
    "                          \"Use the min_impurity_decrease parameter instead.\",\n",
    "                          DeprecationWarning)\n",
    "            min_impurity_split = self.min_impurity_split\n",
    "        else:\n",
    "            min_impurity_split = 1e-7\n",
    "\n",
    "        if min_impurity_split < 0.:\n",
    "            raise ValueError(\"min_impurity_split must be greater than \"\n",
    "                             \"or equal to 0\")\n",
    "\n",
    "        if self.min_impurity_decrease < 0.:\n",
    "            raise ValueError(\"min_impurity_decrease must be greater than \"\n",
    "                             \"or equal to 0\")\n",
    "\n",
    "        allowed_presort = ('auto', True, False)\n",
    "        if self.presort not in allowed_presort:\n",
    "            raise ValueError(\"'presort' should be in {}. Got {!r} instead.\"\n",
    "                             .format(allowed_presort, self.presort))\n",
    "\n",
    "        if self.presort is True and issparse(X):\n",
    "            raise ValueError(\"Presorting is not supported for sparse \"\n",
    "                             \"matrices.\")\n",
    "\n",
    "        presort = self.presort\n",
    "        # Allow presort to be 'auto', which means True if the dataset is dense,\n",
    "        # otherwise it will be False.\n",
    "        if self.presort == 'auto':\n",
    "            presort = not issparse(X)\n",
    "\n",
    "        # If multiple trees are built on the same dataset, we only want to\n",
    "        # presort once. Splitters now can accept presorted indices if desired,\n",
    "        # but do not handle any presorting themselves. Ensemble algorithms\n",
    "        # which desire presorting must do presorting themselves and pass that\n",
    "        # matrix into each tree.\n",
    "\n",
    "        \n",
    "        # Build tree\n",
    "        criterion = self.criterion\n",
    "        if not isinstance(criterion, Criterion):\n",
    "            '''\n",
    "            if is_classification:\n",
    "                criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
    "                                                         self.n_classes_)\n",
    "            else:\n",
    "            '''\n",
    "            criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
    "                                                         n_samples)\n",
    "\n",
    "        SPLITTERS = SPARSE_SPLITTERS if issparse(X) else DENSE_SPLITTERS\n",
    "\n",
    "        splitter = self.splitter\n",
    "        if not isinstance(self.splitter, Splitter):\n",
    "            splitter = SPLITTERS[self.splitter](criterion,\n",
    "                                                self.max_features_,\n",
    "                                                min_samples_leaf,\n",
    "                                                min_weight_leaf,\n",
    "                                                random_state,\n",
    "                                                self.presort)\n",
    "\n",
    "        self.tree_ = Tree(self.n_features_, self.n_classes_, self.n_outputs_)\n",
    "\n",
    "        # Use BestFirst if max_leaf_nodes given; use DepthFirst otherwise\n",
    "        if max_leaf_nodes < 0:\n",
    "            builder = DepthFirstTreeBuilder(splitter, min_samples_split,\n",
    "                                            min_samples_leaf,\n",
    "                                            min_weight_leaf,\n",
    "                                            max_depth,\n",
    "                                            self.min_impurity_decrease,\n",
    "                                            min_impurity_split)\n",
    "        else:\n",
    "            builder = BestFirstTreeBuilder(splitter, min_samples_split,\n",
    "                                           min_samples_leaf,\n",
    "                                           min_weight_leaf,\n",
    "                                           max_depth,\n",
    "                                           max_leaf_nodes,\n",
    "                                           self.min_impurity_decrease,\n",
    "                                           min_impurity_split)\n",
    "\n",
    "        builder.build(self.tree_, X, y, sample_weight, X_idx_sorted)\n",
    "\n",
    "        if self.n_outputs_ == 1:\n",
    "            self.n_classes_ = self.n_classes_[0]\n",
    "            self.classes_ = self.classes_[0]\n",
    "\n",
    "        return self\n",
    "    def predict(self, X, check_input=True):\n",
    "        check_is_fitted(self, 'tree_')\n",
    "        X = self._validate_X_predict(X, check_input)\n",
    "        proba = self.tree_.predict(X)\n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        '''\n",
    "        # Classification\n",
    "        if is_classifier(self):\n",
    "            if self.n_outputs_ == 1:\n",
    "                return self.classes_.take(np.argmax(proba, axis=1), axis=0)\n",
    "\n",
    "            else:\n",
    "                class_type = self.classes_[0].dtype\n",
    "                predictions = np.zeros((n_samples, self.n_outputs_),\n",
    "                                       dtype=class_type)\n",
    "                for k in range(self.n_outputs_):\n",
    "                    predictions[:, k] = self.classes_[k].take(\n",
    "                        np.argmax(proba[:, k], axis=1),\n",
    "                        axis=0)\n",
    "\n",
    "                return predictions\n",
    "\n",
    "        # Regression\n",
    "        else:\n",
    "        '''\n",
    "        if self.n_outputs_ == 1:\n",
    "            return proba[:, 0]\n",
    "\n",
    "        else:\n",
    "            return proba[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = MyRegressionTree()\n",
    "iris = load_iris()\n",
    "model.fit(iris.data, iris.target)\n",
    "result = model.predict(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals.six import StringIO\n",
    "import pydotplus\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "\n",
    "dot_data = StringIO()\n",
    "labels = ['F1', 'F2', 'F3', 'F4']\n",
    "tree.export_graphviz(model, out_file=dot_data, feature_names = labels, class_names = model.classes_, filled=True, rounded=True, special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "graph.write_pdf('MyRegressionTree.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
