{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义回归决策树\n",
    "算法介绍：CART回归树样本空间细分为若干个子空间，子空间内样本的输出y（连续值）的均值即为该子空间内的预测值。故对于输入X为一维时，预测结果可表示为阶梯函数。  \n",
    "评估方式采用**平方误差**：$y_i$属于某个数据集，c为该数据上输出向量y的均值。\n",
    "$$\n",
    "err = \\sum(y_i - c)^2\n",
    "$$\n",
    "\n",
    "算法过程：  \n",
    "输入：训练数据集$D$；  \n",
    "输出：回归树$f(x)$  \n",
    "在训练数据集所在的输入空间中，递归地将每个区域划分为两个子区域并决定每个子区域上的输出值，构建二叉决策树：  \n",
    "（1）选择最优切分变量$j$与切分点$s$，求解\n",
    "$$\n",
    "\\min_{j,s}[\\min_{c_1}\\sum_{x_i\\in R_1(j,s)}(y_i - c_1)^2 + \\min_{c_2}\\sum_{x_i\\in R_2(j, s)}(y_i-c_2)^2]\n",
    "$$\n",
    "遍历变量$j$，对固定的切分变量扫描切分点$s$，选择使得上式达到最小值的对$(j,s)$.  \n",
    "（2）用选定的对$(j,s)$划分区域并决定相应的输出值：\n",
    "$$\n",
    "R_1(j,s) = \\{x|x^{(j)} \\le s \\},R_2(j,s) = \\{x|x^{(j)} \\gt s \\} \\\\\n",
    "\\hat{c}_m = \\frac{1}{N_m} \\sum_{x_i\\in R_m(j, s) y_i}, x \\in R_m, m=1,2\n",
    "$$  \n",
    "（3）继续对两个子区域调用步骤（1）和（2），直至满足停止条件  \n",
    "（4）将输入空间划分为$M$个区域$R_1, R_2, \\dots, R_M$，生成决策树：\n",
    "$$\n",
    "f(x) = \\sum^M_{m=1}\\hat{c}_mI(x\\in R_m)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最小二乘损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def err(dataSet):\n",
    "    return np.var(dataSet[:, -1]) * shape(dataSet)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataSet(dataSet, feature, value):\n",
    "    '''\n",
    "    Input:\n",
    "        dataSet：当前数据集\n",
    "        feature：切分变量[列名]\n",
    "        value：划分点\n",
    "    Output:\n",
    "        dataSet1：在feature上<=value的子数据集\n",
    "        dataSet2：在feature上>value的子数据集\n",
    "    '''\n",
    "    dataSet1 = dataSet[dataSet[:, feature] <= value] # 左边\n",
    "    dataSet2 = dataSet[dataSet[:, feature] > value] # 右边\n",
    "    return dataSet1, dataSet2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选择最好的特征用于划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestFeature(dataSet, min_sample=4, epsilon=0.5):\n",
    "    '''\n",
    "    Input:\n",
    "        dataSet：当前数据集\n",
    "        min_sample：每次划分后，每部分最少的数据数量\n",
    "        epsilon：误差下降阈值，值越大树的深度越大\n",
    "    Output:\n",
    "        bestColumn：最优划分属性\n",
    "        bestValue：最优划分点\n",
    "    '''\n",
    "    features = dataSet.shape[1] - 1 # 特征数量（除去最后一列的标签值）\n",
    "    sErr = err(dataSet) # 当前数据集的损失\n",
    "    minErr = np.inf # 初始化最小误差\n",
    "    bestColumn = 0 # 最优划分特征\n",
    "    bestValue = 0 # 最优划分值\n",
    "    nowErr = 0 # 当前误差\n",
    "    \n",
    "    # 如果数据都是一类，无须进行划分\n",
    "    if len(np.unique(dataSet[:, -1].T.tolist())) == 1:\n",
    "        return None, np.mean(dataSet[:, -1])\n",
    "    # 每个特征循环，寻找最优特征\n",
    "    for feature in range(0, features):\n",
    "        # 遍历每一行数据，寻找最优划分点\n",
    "        for row in range(0, dataSet.shape[0]):\n",
    "            dataSet1, dataSet2 = splitDataSet(dataSet, feature, dataSet[row, feature]) # 划分后的数据\n",
    "            # 不满足min_sample，直接跳过这种不合法的划分\n",
    "            if len(dataSet1) < min_sample or len(dataSet2) < min_sample:\n",
    "                continue\n",
    "            # 计算当前这种划分的误差\n",
    "            nowErr = err(dataSet1) + err(dataSet2)\n",
    "            # 维护最优的划分（最优属性和对应的最优划分点）\n",
    "            if nowErr < minErr:\n",
    "                minErr = nowErr\n",
    "                bestColumn = feature\n",
    "                bestValue = dataSet[row, feature]\n",
    "    # 当划分前后误差下降较小时，直接返回\n",
    "    if (sErr - minErr) < epsilon:\n",
    "        return None, np.mean(dataSet[:, -1])\n",
    "    \n",
    "    # 获得当前最优划分\n",
    "    dataSet1, dataSet2 = splitDataSet(dataSet, bestColumn, bestValue)\n",
    "    if len(dataSet1) < min_sample or len(dataSet2) < min_sample:\n",
    "        return None, np.mean(dataSet[:, -1])\n",
    "    \n",
    "    return bestColumn, bestValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建回归树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(dataSet):\n",
    "    '''\n",
    "    Input:\n",
    "        dataSet: 数据集D\n",
    "    Output:\n",
    "        决策树T\n",
    "    '''\n",
    "    bestColumn, bestValue = chooseBestFeature(dataSet)\n",
    "    if bestColumn == None:\n",
    "        return bestValue\n",
    "    retTree = {} # 初始化决策树\n",
    "    retTree['spCol'] = bestColumn # 最优划分属性（列）\n",
    "    retTree['spVal'] = bestValue # 最优分割值\n",
    "    lSet,rSet = splitDataSet(dataSet, bestColumn, bestValue) # 最优划分\n",
    "    retTree['left'] = createTree(lSet)\n",
    "    retTree['right'] = createTree(rSet)\n",
    "    return retTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(tree, testData):\n",
    "    if shape(testData)[0] == 0:\n",
    "        return getMean(tree)\n",
    "    if (isTree(tree['right']) or isTree(tree['left'])):\n",
    "        lSet, rSet = splitDataSet(testData, tree['spCol'], tree['spVal'])\n",
    "    if isTree(tree['left']):\n",
    "        tree['left'] = prune(tree['left'], lSet)\n",
    "    if isTree(tree['right']):\n",
    "        tree['right'] = prune(tree['right'], rSet)\n",
    "        \n",
    "    # 如果两个分支不再是子树，合并\n",
    "    # 合并前后的误差进行比较，如果合并后的误差比较小，则合并，否则不操作\n",
    "    if not isTree(tree['left']) and not isTree(tree['right']):\n",
    "        lSet, rSet = splitDataSet(testData, tree['spCol'], tree['spVal'])\n",
    "        errMerge = err(dataSet)\n",
    "        errNoMerge = err(lSet) + err(rSet)\n",
    "        if errMerge > errNoMerge:\n",
    "            print('merging')\n",
    "            return (tree['left'] + tree['right']) / 2.0\n",
    "        else:\n",
    "            return tree\n",
    "        \n",
    "def isTree(obj):\n",
    "    return (type(obj).__name__ == 'dict')\n",
    "\n",
    "def getMean(obj):\n",
    "    if isTree(tree['right']):\n",
    "        tree['right'] = getMean(tree['right'])\n",
    "        tree['left'] = getMean(tree['left'])\n",
    "        return (tree['left'] + tree['right']) / 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSample(Tree, testData):\n",
    "    if not isTree(Tree):\n",
    "        return float(tree)\n",
    "    \n",
    "    # 数据比当前节点小，去左子树\n",
    "    if testData[0, Tree['spCol']] < Tree['spVal']:\n",
    "        if isTree(Tree['left']):\n",
    "            return predictSample(Tree['left'], testData)\n",
    "        else:\n",
    "            return float(Tree['left'])\n",
    "    else:\n",
    "        if isTree(Tree['right']):\n",
    "            return predictSample(Tree['right'], testData)\n",
    "        else:\n",
    "            return float(Tree['right'])\n",
    "        \n",
    "def predict(Tree, testData):\n",
    "    m = shape(testData)[0]\n",
    "    y_pred = mat(zeros((m, 1)))\n",
    "    \n",
    "    for i in range(m):\n",
    "        y_pred[i, 0] = predictSample(Tree, testData[i])\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据集\n",
    "def loadData(filaName):\n",
    "    dataSet = []\n",
    "    fr = open(filaName)\n",
    "    for line in fr.readlines():\n",
    "        curLine = line.strip().split('\\t')\n",
    "        theLine = []\n",
    "        for item in curLine:\n",
    "            item = float(item)\n",
    "            theLine.append(item)\n",
    "        dataSet.append(theLine)\n",
    "    return dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2 0. ]\n",
      " [4.9 3.  1.4 0.2 0. ]\n",
      " [4.7 3.2 1.3 0.2 0. ]\n",
      " [4.6 3.1 1.5 0.2 0. ]\n",
      " [5.  3.6 1.4 0.2 0. ]\n",
      " [5.4 3.9 1.7 0.4 0. ]\n",
      " [4.6 3.4 1.4 0.3 0. ]\n",
      " [5.  3.4 1.5 0.2 0. ]\n",
      " [4.4 2.9 1.4 0.2 0. ]\n",
      " [4.9 3.1 1.5 0.1 0. ]\n",
      " [5.4 3.7 1.5 0.2 0. ]\n",
      " [4.8 3.4 1.6 0.2 0. ]\n",
      " [4.8 3.  1.4 0.1 0. ]\n",
      " [4.3 3.  1.1 0.1 0. ]\n",
      " [5.8 4.  1.2 0.2 0. ]\n",
      " [5.7 4.4 1.5 0.4 0. ]\n",
      " [5.4 3.9 1.3 0.4 0. ]\n",
      " [5.1 3.5 1.4 0.3 0. ]\n",
      " [5.7 3.8 1.7 0.3 0. ]\n",
      " [5.1 3.8 1.5 0.3 0. ]\n",
      " [5.4 3.4 1.7 0.2 0. ]\n",
      " [5.1 3.7 1.5 0.4 0. ]\n",
      " [4.6 3.6 1.  0.2 0. ]\n",
      " [5.1 3.3 1.7 0.5 0. ]\n",
      " [4.8 3.4 1.9 0.2 0. ]\n",
      " [5.  3.  1.6 0.2 0. ]\n",
      " [5.  3.4 1.6 0.4 0. ]\n",
      " [5.2 3.5 1.5 0.2 0. ]\n",
      " [5.2 3.4 1.4 0.2 0. ]\n",
      " [4.7 3.2 1.6 0.2 0. ]\n",
      " [4.8 3.1 1.6 0.2 0. ]\n",
      " [5.4 3.4 1.5 0.4 0. ]\n",
      " [5.2 4.1 1.5 0.1 0. ]\n",
      " [5.5 4.2 1.4 0.2 0. ]\n",
      " [4.9 3.1 1.5 0.2 0. ]\n",
      " [5.  3.2 1.2 0.2 0. ]\n",
      " [5.5 3.5 1.3 0.2 0. ]\n",
      " [4.9 3.6 1.4 0.1 0. ]\n",
      " [4.4 3.  1.3 0.2 0. ]\n",
      " [5.1 3.4 1.5 0.2 0. ]\n",
      " [5.  3.5 1.3 0.3 0. ]\n",
      " [4.5 2.3 1.3 0.3 0. ]\n",
      " [4.4 3.2 1.3 0.2 0. ]\n",
      " [5.  3.5 1.6 0.6 0. ]\n",
      " [5.1 3.8 1.9 0.4 0. ]\n",
      " [4.8 3.  1.4 0.3 0. ]\n",
      " [5.1 3.8 1.6 0.2 0. ]\n",
      " [4.6 3.2 1.4 0.2 0. ]\n",
      " [5.3 3.7 1.5 0.2 0. ]\n",
      " [5.  3.3 1.4 0.2 0. ]\n",
      " [7.  3.2 4.7 1.4 1. ]\n",
      " [6.4 3.2 4.5 1.5 1. ]\n",
      " [6.9 3.1 4.9 1.5 1. ]\n",
      " [5.5 2.3 4.  1.3 1. ]\n",
      " [6.5 2.8 4.6 1.5 1. ]\n",
      " [5.7 2.8 4.5 1.3 1. ]\n",
      " [6.3 3.3 4.7 1.6 1. ]\n",
      " [4.9 2.4 3.3 1.  1. ]\n",
      " [6.6 2.9 4.6 1.3 1. ]\n",
      " [5.2 2.7 3.9 1.4 1. ]\n",
      " [5.  2.  3.5 1.  1. ]\n",
      " [5.9 3.  4.2 1.5 1. ]\n",
      " [6.  2.2 4.  1.  1. ]\n",
      " [6.1 2.9 4.7 1.4 1. ]\n",
      " [5.6 2.9 3.6 1.3 1. ]\n",
      " [6.7 3.1 4.4 1.4 1. ]\n",
      " [5.6 3.  4.5 1.5 1. ]\n",
      " [5.8 2.7 4.1 1.  1. ]\n",
      " [6.2 2.2 4.5 1.5 1. ]\n",
      " [5.6 2.5 3.9 1.1 1. ]\n",
      " [5.9 3.2 4.8 1.8 1. ]\n",
      " [6.1 2.8 4.  1.3 1. ]\n",
      " [6.3 2.5 4.9 1.5 1. ]\n",
      " [6.1 2.8 4.7 1.2 1. ]\n",
      " [6.4 2.9 4.3 1.3 1. ]\n",
      " [6.6 3.  4.4 1.4 1. ]\n",
      " [6.8 2.8 4.8 1.4 1. ]\n",
      " [6.7 3.  5.  1.7 1. ]\n",
      " [6.  2.9 4.5 1.5 1. ]\n",
      " [5.7 2.6 3.5 1.  1. ]\n",
      " [5.5 2.4 3.8 1.1 1. ]\n",
      " [5.5 2.4 3.7 1.  1. ]\n",
      " [5.8 2.7 3.9 1.2 1. ]\n",
      " [6.  2.7 5.1 1.6 1. ]\n",
      " [5.4 3.  4.5 1.5 1. ]\n",
      " [6.  3.4 4.5 1.6 1. ]\n",
      " [6.7 3.1 4.7 1.5 1. ]\n",
      " [6.3 2.3 4.4 1.3 1. ]\n",
      " [5.6 3.  4.1 1.3 1. ]\n",
      " [5.5 2.5 4.  1.3 1. ]\n",
      " [5.5 2.6 4.4 1.2 1. ]\n",
      " [6.1 3.  4.6 1.4 1. ]\n",
      " [5.8 2.6 4.  1.2 1. ]\n",
      " [5.  2.3 3.3 1.  1. ]\n",
      " [5.6 2.7 4.2 1.3 1. ]\n",
      " [5.7 3.  4.2 1.2 1. ]\n",
      " [5.7 2.9 4.2 1.3 1. ]\n",
      " [6.2 2.9 4.3 1.3 1. ]\n",
      " [5.1 2.5 3.  1.1 1. ]\n",
      " [5.7 2.8 4.1 1.3 1. ]\n",
      " [6.3 3.3 6.  2.5 2. ]\n",
      " [5.8 2.7 5.1 1.9 2. ]\n",
      " [7.1 3.  5.9 2.1 2. ]\n",
      " [6.3 2.9 5.6 1.8 2. ]\n",
      " [6.5 3.  5.8 2.2 2. ]\n",
      " [7.6 3.  6.6 2.1 2. ]\n",
      " [4.9 2.5 4.5 1.7 2. ]\n",
      " [7.3 2.9 6.3 1.8 2. ]\n",
      " [6.7 2.5 5.8 1.8 2. ]\n",
      " [7.2 3.6 6.1 2.5 2. ]\n",
      " [6.5 3.2 5.1 2.  2. ]\n",
      " [6.4 2.7 5.3 1.9 2. ]\n",
      " [6.8 3.  5.5 2.1 2. ]\n",
      " [5.7 2.5 5.  2.  2. ]\n",
      " [5.8 2.8 5.1 2.4 2. ]\n",
      " [6.4 3.2 5.3 2.3 2. ]\n",
      " [6.5 3.  5.5 1.8 2. ]\n",
      " [7.7 3.8 6.7 2.2 2. ]\n",
      " [7.7 2.6 6.9 2.3 2. ]\n",
      " [6.  2.2 5.  1.5 2. ]\n",
      " [6.9 3.2 5.7 2.3 2. ]\n",
      " [5.6 2.8 4.9 2.  2. ]\n",
      " [7.7 2.8 6.7 2.  2. ]\n",
      " [6.3 2.7 4.9 1.8 2. ]\n",
      " [6.7 3.3 5.7 2.1 2. ]\n",
      " [7.2 3.2 6.  1.8 2. ]\n",
      " [6.2 2.8 4.8 1.8 2. ]\n",
      " [6.1 3.  4.9 1.8 2. ]\n",
      " [6.4 2.8 5.6 2.1 2. ]\n",
      " [7.2 3.  5.8 1.6 2. ]\n",
      " [7.4 2.8 6.1 1.9 2. ]\n",
      " [7.9 3.8 6.4 2.  2. ]\n",
      " [6.4 2.8 5.6 2.2 2. ]\n",
      " [6.3 2.8 5.1 1.5 2. ]\n",
      " [6.1 2.6 5.6 1.4 2. ]\n",
      " [7.7 3.  6.1 2.3 2. ]\n",
      " [6.3 3.4 5.6 2.4 2. ]\n",
      " [6.4 3.1 5.5 1.8 2. ]\n",
      " [6.  3.  4.8 1.8 2. ]\n",
      " [6.9 3.1 5.4 2.1 2. ]\n",
      " [6.7 3.1 5.6 2.4 2. ]\n",
      " [6.9 3.1 5.1 2.3 2. ]\n",
      " [5.8 2.7 5.1 1.9 2. ]\n",
      " [6.8 3.2 5.9 2.3 2. ]\n",
      " [6.7 3.3 5.7 2.5 2. ]\n",
      " [6.7 3.  5.2 2.3 2. ]\n",
      " [6.3 2.5 5.  1.9 2. ]\n",
      " [6.5 3.  5.2 2.  2. ]\n",
      " [6.2 3.4 5.4 2.3 2. ]\n",
      " [5.9 3.  5.1 1.8 2. ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "dataSet=np.column_stack((x,y.reshape((-1,1))))\n",
    "print(dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mytree\n",
      " {'spCol': 2, 'spVal': 1.9, 'left': 0.0, 'right': {'spCol': 3, 'spVal': 1.7, 'left': {'spCol': 2, 'spVal': 4.9, 'left': 1.0208333333333333, 'right': 1.6666666666666667}, 'right': 1.9782608695652173}}\n"
     ]
    }
   ],
   "source": [
    "mytree=createTree(dataSet) \n",
    "print('mytree\\n',mytree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 封装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRegressionTree():\n",
    "    def __init__(self):\n",
    "        return\n",
    "    def err(self, dataSet):\n",
    "        return np.var(dataSet[:, -1]) * shape(dataSet)[0]\n",
    "    \n",
    "    def splitDataSet(self, dataSet, feature, value):\n",
    "        '''\n",
    "        Input:\n",
    "            dataSet：当前数据集\n",
    "            feature：切分变量[列名]\n",
    "            value：划分点\n",
    "        Output:\n",
    "            dataSet1：在feature上<=value的子数据集\n",
    "            dataSet2：在feature上>value的子数据集\n",
    "        '''\n",
    "        dataSet1 = dataSet[dataSet[:, feature] <= value] # 左边\n",
    "        dataSet2 = dataSet[dataSet[:, feature] > value] # 右边\n",
    "        return dataSet1, dataSet2\n",
    "    \n",
    "    def chooseBestFeature(self, dataSet, min_sample=4, epsilon=0.5):\n",
    "        '''\n",
    "        Input:\n",
    "            dataSet：当前数据集\n",
    "            min_sample：每次划分后，每部分最少的数据数量\n",
    "            epsilon：误差下降阈值，值越大树的深度越大\n",
    "        Output:\n",
    "            bestColumn：最优划分属性\n",
    "            bestValue：最优划分点\n",
    "        '''\n",
    "        features = dataSet.shape[1] - 1 # 特征数量（除去最后一列的标签值）\n",
    "        sErr = err(dataSet) # 当前数据集的损失\n",
    "        minErr = np.inf # 初始化最小误差\n",
    "        bestColumn = 0 # 最优划分特征\n",
    "        bestValue = 0 # 最优划分值\n",
    "        nowErr = 0 # 当前误差\n",
    "\n",
    "        # 如果数据都是一类，无须进行划分\n",
    "        if len(np.unique(dataSet[:, -1].T.tolist())) == 1:\n",
    "            return None, np.mean(dataSet[:, -1])\n",
    "        # 每个特征循环，寻找最优特征\n",
    "        for feature in range(0, features):\n",
    "            # 遍历每一行数据，寻找最优划分点\n",
    "            for row in range(0, dataSet.shape[0]):\n",
    "                dataSet1, dataSet2 = splitDataSet(dataSet, feature, dataSet[row, feature]) # 划分后的数据\n",
    "                # 不满足min_sample，直接跳过这种不合法的划分\n",
    "                if len(dataSet1) < min_sample or len(dataSet2) < min_sample:\n",
    "                    continue\n",
    "                # 计算当前这种划分的误差\n",
    "                nowErr = err(dataSet1) + err(dataSet2)\n",
    "                # 维护最优的划分（最优属性和对应的最优划分点）\n",
    "                if nowErr < minErr:\n",
    "                    minErr = nowErr\n",
    "                    bestColumn = feature\n",
    "                    bestValue = dataSet[row, feature]\n",
    "        # 当划分前后误差下降较小时，直接返回\n",
    "        if (sErr - minErr) < epsilon:\n",
    "            return None, np.mean(dataSet[:, -1])\n",
    "\n",
    "        # 获得当前最优划分\n",
    "        dataSet1, dataSet2 = splitDataSet(dataSet, bestColumn, bestValue)\n",
    "        if len(dataSet1) < min_sample or len(dataSet2) < min_sample:\n",
    "            return None, np.mean(dataSet[:, -1])\n",
    "\n",
    "        return bestColumn, bestValue\n",
    "\n",
    "    def createTree(self, dataSet):\n",
    "        '''\n",
    "        Input:\n",
    "            dataSet: 数据集D\n",
    "        Output:\n",
    "            决策树T\n",
    "        '''\n",
    "        bestColumn, bestValue = chooseBestFeature(dataSet)\n",
    "        if bestColumn == None:\n",
    "            return bestValue\n",
    "        retTree = {} # 初始化决策树\n",
    "        retTree['spCol'] = bestColumn # 最优划分属性（列）\n",
    "        retTree['spVal'] = bestValue # 最优分割值\n",
    "        lSet,rSet = splitDataSet(dataSet, bestColumn, bestValue) # 最优划分\n",
    "        retTree['left'] = createTree(lSet)\n",
    "        retTree['right'] = createTree(rSet)\n",
    "        return retTree\n",
    "    \n",
    "    def prune(self, tree, testData):\n",
    "        if shape(testData)[0] == 0:\n",
    "            return getMean(tree)\n",
    "        if (isTree(tree['right']) or isTree(tree['left'])):\n",
    "            lSet, rSet = splitDataSet(testData, tree['spCol'], tree['spVal'])\n",
    "        if isTree(tree['left']):\n",
    "            tree['left'] = prune(tree['left'], lSet)\n",
    "        if isTree(tree['right']):\n",
    "            tree['right'] = prune(tree['right'], rSet)\n",
    "\n",
    "        # 如果两个分支不再是子树，合并\n",
    "        # 合并前后的误差进行比较，如果合并后的误差比较小，则合并，否则不操作\n",
    "        if not isTree(tree['left']) and not isTree(tree['right']):\n",
    "            lSet, rSet = splitDataSet(testData, tree['spCol'], tree['spVal'])\n",
    "            errMerge = err(dataSet)\n",
    "            errNoMerge = err(lSet) + err(rSet)\n",
    "            if errMerge > errNoMerge:\n",
    "                print('merging')\n",
    "                return (tree['left'] + tree['right']) / 2.0\n",
    "            else:\n",
    "                return tree\n",
    "\n",
    "    def isTree(self, obj):\n",
    "        return (type(obj).__name__ == 'dict')\n",
    "\n",
    "    def getMean(self, obj):\n",
    "        if isTree(tree['right']):\n",
    "            tree['right'] = getMean(tree['right'])\n",
    "            tree['left'] = getMean(tree['left'])\n",
    "            return (tree['left'] + tree['right']) / 2.0\n",
    "        \n",
    "    # 导入数据集\n",
    "    def loadData(self, filaName):\n",
    "        dataSet = []\n",
    "        fr = open(filaName)\n",
    "        for line in fr.readlines():\n",
    "            curLine = line.strip().split('\\t')\n",
    "            theLine = []\n",
    "            for item in curLine:\n",
    "                item = float(item)\n",
    "                theLine.append(item)\n",
    "            dataSet.append(theLine)\n",
    "        return dataSet\n",
    "    def getTree(self):\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2 0. ]\n",
      " [4.9 3.  1.4 0.2 0. ]\n",
      " [4.7 3.2 1.3 0.2 0. ]\n",
      " [4.6 3.1 1.5 0.2 0. ]\n",
      " [5.  3.6 1.4 0.2 0. ]\n",
      " [5.4 3.9 1.7 0.4 0. ]\n",
      " [4.6 3.4 1.4 0.3 0. ]\n",
      " [5.  3.4 1.5 0.2 0. ]\n",
      " [4.4 2.9 1.4 0.2 0. ]\n",
      " [4.9 3.1 1.5 0.1 0. ]\n",
      " [5.4 3.7 1.5 0.2 0. ]\n",
      " [4.8 3.4 1.6 0.2 0. ]\n",
      " [4.8 3.  1.4 0.1 0. ]\n",
      " [4.3 3.  1.1 0.1 0. ]\n",
      " [5.8 4.  1.2 0.2 0. ]\n",
      " [5.7 4.4 1.5 0.4 0. ]\n",
      " [5.4 3.9 1.3 0.4 0. ]\n",
      " [5.1 3.5 1.4 0.3 0. ]\n",
      " [5.7 3.8 1.7 0.3 0. ]\n",
      " [5.1 3.8 1.5 0.3 0. ]\n",
      " [5.4 3.4 1.7 0.2 0. ]\n",
      " [5.1 3.7 1.5 0.4 0. ]\n",
      " [4.6 3.6 1.  0.2 0. ]\n",
      " [5.1 3.3 1.7 0.5 0. ]\n",
      " [4.8 3.4 1.9 0.2 0. ]\n",
      " [5.  3.  1.6 0.2 0. ]\n",
      " [5.  3.4 1.6 0.4 0. ]\n",
      " [5.2 3.5 1.5 0.2 0. ]\n",
      " [5.2 3.4 1.4 0.2 0. ]\n",
      " [4.7 3.2 1.6 0.2 0. ]\n",
      " [4.8 3.1 1.6 0.2 0. ]\n",
      " [5.4 3.4 1.5 0.4 0. ]\n",
      " [5.2 4.1 1.5 0.1 0. ]\n",
      " [5.5 4.2 1.4 0.2 0. ]\n",
      " [4.9 3.1 1.5 0.2 0. ]\n",
      " [5.  3.2 1.2 0.2 0. ]\n",
      " [5.5 3.5 1.3 0.2 0. ]\n",
      " [4.9 3.6 1.4 0.1 0. ]\n",
      " [4.4 3.  1.3 0.2 0. ]\n",
      " [5.1 3.4 1.5 0.2 0. ]\n",
      " [5.  3.5 1.3 0.3 0. ]\n",
      " [4.5 2.3 1.3 0.3 0. ]\n",
      " [4.4 3.2 1.3 0.2 0. ]\n",
      " [5.  3.5 1.6 0.6 0. ]\n",
      " [5.1 3.8 1.9 0.4 0. ]\n",
      " [4.8 3.  1.4 0.3 0. ]\n",
      " [5.1 3.8 1.6 0.2 0. ]\n",
      " [4.6 3.2 1.4 0.2 0. ]\n",
      " [5.3 3.7 1.5 0.2 0. ]\n",
      " [5.  3.3 1.4 0.2 0. ]\n",
      " [7.  3.2 4.7 1.4 1. ]\n",
      " [6.4 3.2 4.5 1.5 1. ]\n",
      " [6.9 3.1 4.9 1.5 1. ]\n",
      " [5.5 2.3 4.  1.3 1. ]\n",
      " [6.5 2.8 4.6 1.5 1. ]\n",
      " [5.7 2.8 4.5 1.3 1. ]\n",
      " [6.3 3.3 4.7 1.6 1. ]\n",
      " [4.9 2.4 3.3 1.  1. ]\n",
      " [6.6 2.9 4.6 1.3 1. ]\n",
      " [5.2 2.7 3.9 1.4 1. ]\n",
      " [5.  2.  3.5 1.  1. ]\n",
      " [5.9 3.  4.2 1.5 1. ]\n",
      " [6.  2.2 4.  1.  1. ]\n",
      " [6.1 2.9 4.7 1.4 1. ]\n",
      " [5.6 2.9 3.6 1.3 1. ]\n",
      " [6.7 3.1 4.4 1.4 1. ]\n",
      " [5.6 3.  4.5 1.5 1. ]\n",
      " [5.8 2.7 4.1 1.  1. ]\n",
      " [6.2 2.2 4.5 1.5 1. ]\n",
      " [5.6 2.5 3.9 1.1 1. ]\n",
      " [5.9 3.2 4.8 1.8 1. ]\n",
      " [6.1 2.8 4.  1.3 1. ]\n",
      " [6.3 2.5 4.9 1.5 1. ]\n",
      " [6.1 2.8 4.7 1.2 1. ]\n",
      " [6.4 2.9 4.3 1.3 1. ]\n",
      " [6.6 3.  4.4 1.4 1. ]\n",
      " [6.8 2.8 4.8 1.4 1. ]\n",
      " [6.7 3.  5.  1.7 1. ]\n",
      " [6.  2.9 4.5 1.5 1. ]\n",
      " [5.7 2.6 3.5 1.  1. ]\n",
      " [5.5 2.4 3.8 1.1 1. ]\n",
      " [5.5 2.4 3.7 1.  1. ]\n",
      " [5.8 2.7 3.9 1.2 1. ]\n",
      " [6.  2.7 5.1 1.6 1. ]\n",
      " [5.4 3.  4.5 1.5 1. ]\n",
      " [6.  3.4 4.5 1.6 1. ]\n",
      " [6.7 3.1 4.7 1.5 1. ]\n",
      " [6.3 2.3 4.4 1.3 1. ]\n",
      " [5.6 3.  4.1 1.3 1. ]\n",
      " [5.5 2.5 4.  1.3 1. ]\n",
      " [5.5 2.6 4.4 1.2 1. ]\n",
      " [6.1 3.  4.6 1.4 1. ]\n",
      " [5.8 2.6 4.  1.2 1. ]\n",
      " [5.  2.3 3.3 1.  1. ]\n",
      " [5.6 2.7 4.2 1.3 1. ]\n",
      " [5.7 3.  4.2 1.2 1. ]\n",
      " [5.7 2.9 4.2 1.3 1. ]\n",
      " [6.2 2.9 4.3 1.3 1. ]\n",
      " [5.1 2.5 3.  1.1 1. ]\n",
      " [5.7 2.8 4.1 1.3 1. ]\n",
      " [6.3 3.3 6.  2.5 2. ]\n",
      " [5.8 2.7 5.1 1.9 2. ]\n",
      " [7.1 3.  5.9 2.1 2. ]\n",
      " [6.3 2.9 5.6 1.8 2. ]\n",
      " [6.5 3.  5.8 2.2 2. ]\n",
      " [7.6 3.  6.6 2.1 2. ]\n",
      " [4.9 2.5 4.5 1.7 2. ]\n",
      " [7.3 2.9 6.3 1.8 2. ]\n",
      " [6.7 2.5 5.8 1.8 2. ]\n",
      " [7.2 3.6 6.1 2.5 2. ]\n",
      " [6.5 3.2 5.1 2.  2. ]\n",
      " [6.4 2.7 5.3 1.9 2. ]\n",
      " [6.8 3.  5.5 2.1 2. ]\n",
      " [5.7 2.5 5.  2.  2. ]\n",
      " [5.8 2.8 5.1 2.4 2. ]\n",
      " [6.4 3.2 5.3 2.3 2. ]\n",
      " [6.5 3.  5.5 1.8 2. ]\n",
      " [7.7 3.8 6.7 2.2 2. ]\n",
      " [7.7 2.6 6.9 2.3 2. ]\n",
      " [6.  2.2 5.  1.5 2. ]\n",
      " [6.9 3.2 5.7 2.3 2. ]\n",
      " [5.6 2.8 4.9 2.  2. ]\n",
      " [7.7 2.8 6.7 2.  2. ]\n",
      " [6.3 2.7 4.9 1.8 2. ]\n",
      " [6.7 3.3 5.7 2.1 2. ]\n",
      " [7.2 3.2 6.  1.8 2. ]\n",
      " [6.2 2.8 4.8 1.8 2. ]\n",
      " [6.1 3.  4.9 1.8 2. ]\n",
      " [6.4 2.8 5.6 2.1 2. ]\n",
      " [7.2 3.  5.8 1.6 2. ]\n",
      " [7.4 2.8 6.1 1.9 2. ]\n",
      " [7.9 3.8 6.4 2.  2. ]\n",
      " [6.4 2.8 5.6 2.2 2. ]\n",
      " [6.3 2.8 5.1 1.5 2. ]\n",
      " [6.1 2.6 5.6 1.4 2. ]\n",
      " [7.7 3.  6.1 2.3 2. ]\n",
      " [6.3 3.4 5.6 2.4 2. ]\n",
      " [6.4 3.1 5.5 1.8 2. ]\n",
      " [6.  3.  4.8 1.8 2. ]\n",
      " [6.9 3.1 5.4 2.1 2. ]\n",
      " [6.7 3.1 5.6 2.4 2. ]\n",
      " [6.9 3.1 5.1 2.3 2. ]\n",
      " [5.8 2.7 5.1 1.9 2. ]\n",
      " [6.8 3.2 5.9 2.3 2. ]\n",
      " [6.7 3.3 5.7 2.5 2. ]\n",
      " [6.7 3.  5.2 2.3 2. ]\n",
      " [6.3 2.5 5.  1.9 2. ]\n",
      " [6.5 3.  5.2 2.  2. ]\n",
      " [6.2 3.4 5.4 2.3 2. ]\n",
      " [5.9 3.  5.1 1.8 2. ]]\n",
      "mytree\n",
      " {'spCol': 2, 'spVal': 1.9, 'left': 0.0, 'right': {'spCol': 3, 'spVal': 1.7, 'left': {'spCol': 2, 'spVal': 4.9, 'left': 1.0208333333333333, 'right': 1.6666666666666667}, 'right': 1.9782608695652173}}\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "dataSet=np.column_stack((x,y.reshape((-1,1))))\n",
    "print(dataSet)\n",
    "\n",
    "mytree = SimpleRegressionTree()\n",
    "tree = mytree.createTree(dataSet)\n",
    "print('mytree\\n',tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
